{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd3d12af-3749-42a0-9733-a2ee43c0504d",
   "metadata": {},
   "source": [
    "# Text Summarization - with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d98e4de2-990f-47d5-bb90-abcfe1e2f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import yaml\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import PyPDF2\n",
    "from tqdm import tqdm\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader ,TextLoader\n",
    "\n",
    "def initialize_template():\n",
    "    template =\"\"\"You are a text summarizer, summarize the text provided, do to repeat the response.\n",
    "    text:\n",
    "    {content}\"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    return prompt \n",
    "\n",
    "def initialize_gpt():\n",
    "    from langchain.chat_models import AzureChatOpenAI    \n",
    "    %reload_ext dotenv\n",
    "    %dotenv\n",
    "    llm = AzureChatOpenAI(deployment_name=os.getenv('DEPLOYEMENT_NAME'),\n",
    "                        temperature=0.0,\n",
    "                        max_tokens=4000,\n",
    "                        callbacks=[StreamingStdOutCallbackHandler()]\n",
    "                        )\n",
    "    return llm\n",
    "\n",
    "def document_loader(doc_path):\n",
    "    loader = PyPDFLoader(doc_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200, separator=\"\\n\")\n",
    "    docs = text_splitter.split_documents(documents=documents)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f71a898-8660-4e0c-9059-462a2223b15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_path='./data/doc/why_is_DG_imp.pdf'\n",
    "docs = document_loader(doc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "047c9391-8568-4822-9f83-85f72ff8f71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are a text summarizer, summarize the text provided, do to repeat the response.\\n    text:\\n    this is my content'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = initialize_template()\n",
    "prompt.format(content='this is my content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265c04d1-f0d4-4781-8cd0-5e502fd20c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:167: UserWarning: As of openai>=1.0.0, Azure endpoints should be specified via the `azure_endpoint` param not `openai_api_base` (or alias `base_url`). Updating `openai_api_base` from https://hexawarebelfius.openai.azure.com/ to https://hexawarebelfius.openai.azure.com/openai.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:174: UserWarning: As of openai>=1.0.0, if `deployment_name` (or alias `azure_deployment`) is specified then `openai_api_base` (or alias `base_url`) should not be. Instead use `deployment_name` (or alias `azure_deployment`) and `azure_endpoint`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/langchain_community/chat_models/azure_openai.py:182: UserWarning: As of openai>=1.0.0, if `openai_api_base` (or alias `base_url`) is specified it is expected to be of the form https://example-resource.azure.openai.com/openai/deployments/example-deployment. Updating https://hexawarebelfius.openai.azure.com/ to https://hexawarebelfius.openai.azure.com/openai.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = initialize_gpt()\n",
    "chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c132448-65db-4602-8763-1a7f4940d40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:18<00:00,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data governance is crucial for improving an organization's data quality, trust, and understanding by establishing stewardship and a comprehensive business glossary. It is key to digital transformation, ensuring consistent and secure data management according to specific policies and standards. This process enhances data management, accessibility, and collaboration across departments by standardizing terminology, KPIs, rules, and policies. It also breaks down departmental silos, clarifies roles, and improves IT and business integration, empowering users with self-service technology and strategic technology use. The importance of data governance is growing due to its critical role in business operations, driven by an increased reliance on data analytics for decision-making. This need is supported by the demand for organized, clean data for optimal performance, cost efficiency, legal compliance, and improved financial reporting. The evolving business landscape, with more complex data, new technologies, and increasing regulatory demands, highlights the need for effective data governance. Organizations must see data governance as an ongoing effort, adapting to changes in the company and market, investing in technology that automates data processes, and staying updated on industry trends to accelerate digital transformation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "summary=''\n",
    "for chunk in tqdm(docs):\n",
    "    summary = summary+str(chunk)\n",
    "    summary = chain.invoke({\"content\":summary})['text']\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da2890b-76da-468d-86b1-2aef467f6c03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
